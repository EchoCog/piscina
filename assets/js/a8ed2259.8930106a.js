"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[1257],{3279:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>d,contentTitle:()=>s,default:()=>h,frontMatter:()=>a,metadata:()=>r,toc:()=>c});var t=i(4848),o=i(8453);const a={id:"Performance Notes",sidebar_position:2},s=void 0,r={id:"advanced-topics/Performance Notes",title:"Performance Notes",description:"Workers are generally optimized for offloading synchronous,",source:"@site/docs/advanced-topics/performance.mdx",sourceDirName:"advanced-topics",slug:"/advanced-topics/Performance Notes",permalink:"/piscina/advanced-topics/Performance Notes",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:2,frontMatter:{id:"Performance Notes",sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"Custom Task Queues",permalink:"/piscina/advanced-topics/Custom Task Queues"},next:{title:"API Reference",permalink:"/piscina/category/api-reference"}},d={},c=[{value:"Queue Size",id:"queue-size",level:3},{value:"Queue Pressure and Idle Threads",id:"queue-pressure-and-idle-threads",level:3},{value:"Thread priority on Linux systems",id:"thread-priority-on-linux-systems",level:3},{value:"Multiple Thread Pools and Embedding Piscina as a Dependency",id:"multiple-thread-pools-and-embedding-piscina-as-a-dependency",level:3}];function l(e){const n={code:"code",em:"em",h3:"h3",li:"li",p:"p",pre:"pre",ul:"ul",...(0,o.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.p,{children:"Workers are generally optimized for offloading synchronous,\ncompute-intensive operations off the main Node.js event loop thread.\nWhile it is possible to perform asynchronous operations and I/O\nwithin a Worker, the performance advantages of doing so will be\nminimal."}),"\n",(0,t.jsx)(n.p,{children:"Specifically, it is worth noting that asynchronous operations\nwithin Node.js, including I/O such as file system operations\nor CPU-bound tasks such as crypto operations or compression\nalgorithms, are already performed in parallel by Node.js and\nlibuv on a per-process level. This means that there will be\nlittle performance impact on moving such async operations into\na Piscina worker (see examples/scrypt for example)."}),"\n",(0,t.jsx)(n.h3,{id:"queue-size",children:"Queue Size"}),"\n",(0,t.jsxs)(n.p,{children:["Piscina provides the ability to configure the minimum and\nmaximum number of worker threads active in the pool, as well as\nset limits on the number of tasks that may be queued up waiting\nfor a free worker. It is important to note that setting the\n",(0,t.jsx)(n.code,{children:"maxQueue"})," size too high relative to the number of worker threads\ncan have a detrimental impact on performance and memory usage.\nSetting the ",(0,t.jsx)(n.code,{children:"maxQueue"})," size too small can also be problematic\nas doing so could cause your worker threads to become idle and\nbe shutdown. Our testing has shown that a ",(0,t.jsx)(n.code,{children:"maxQueue"})," size of\napproximately the square of the maximum number of threads is\ngenerally sufficient and performs well for many cases, but this\nwill vary significantly depending on your workload. It will be\nimportant to test and benchmark your worker pools to ensure you've\neffectively balanced queue wait times, memory usage, and worker\npool utilization."]}),"\n",(0,t.jsx)(n.h3,{id:"queue-pressure-and-idle-threads",children:"Queue Pressure and Idle Threads"}),"\n",(0,t.jsxs)(n.p,{children:["The thread pool maintained by Piscina has both a minimum and maximum\nlimit to the number of threads that may be created. When a Piscina\ninstance is created, it will spawn the minimum number of threads\nimmediately, then create additional threads as needed up to the\nlimit set by ",(0,t.jsx)(n.code,{children:"maxThreads"}),". Whenever a worker completes a task, a\ncheck is made to determine if there is additional work for it to\nperform. If there is no additional work, the thread is marked idle.\nBy default, idle threads are shutdown immediately, with Piscina\nensuring that the pool always maintains at least the minimum."]}),"\n",(0,t.jsx)(n.p,{children:"When a Piscina pool is processing a stream of tasks (for instance,\nprocessing http server requests as in the React server-side\nrendering example in examples/react-ssr), if the rate in which\nnew tasks are received and queued is not sufficient to keep workers\nfrom going idle and terminating, the pool can experience a thrashing\neffect -- excessively creating and terminating workers that will\ncause a net performance loss. There are a couple of strategies to\navoid this churn:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:'Strategy 1: Ensure that the queue rate of new tasks is sufficient to\nkeep workers from going idle. We refer to this as "queue pressure".\nIf the queue pressure is too low, workers will go idle and terminate.\nIf the queue pressure is too high, tasks will stack up, experience\nincreased wait latency, and consume additional memory.'}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Strategy 2: Increase the ",(0,t.jsx)(n.code,{children:"idleTimeout"})," configuration option. By\ndefault, idle threads terminate immediately. The ",(0,t.jsx)(n.code,{children:"idleTimeout"})," option\ncan be used to specify a longer period of time to wait for additional\ntasks to be submitted before terminating the worker. If the queue\npressure is not maintained, this could result in workers sitting idle\nbut those will have less of a performance impact than the thrashing\nthat occurs when threads are repeatedly terminated and recreated."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Strategy 3: Increase the ",(0,t.jsx)(n.code,{children:"minThreads"})," configuration option. This has\nthe same basic effect as increasing the ",(0,t.jsx)(n.code,{children:"idleTimeout"}),". If the queue\npressure is not high enough, workers may sit idle indefinitely but\nthere will be less of a performance hit."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"In applications using Piscina, it will be most effective to use a\ncombination of these three approaches and tune the various configuration\nparameters to find the optimum combination both for the application\nworkload and the capabilities of the deployment environment. There\nare no one set of options that are going to work best."}),"\n",(0,t.jsx)(n.h3,{id:"thread-priority-on-linux-systems",children:"Thread priority on Linux systems"}),"\n",(0,t.jsxs)(n.p,{children:["On Linux systems that support [",(0,t.jsx)(n.code,{children:"nice(2)"}),"][], Piscina is capable of setting\nthe priority of every worker in the pool. To use this mechanism, an additional\noptional native addon dependency (",(0,t.jsx)(n.code,{children:"nice-napi"}),", ",(0,t.jsx)(n.code,{children:"npm i nice-napi"}),") is required.\nOnce [",(0,t.jsx)(n.code,{children:"nice-napi"}),"][] is installed, creating a ",(0,t.jsx)(n.code,{children:"Piscina"})," instance with the\n",(0,t.jsx)(n.code,{children:"niceIncrement"})," configuration option will set the priority for the pool:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-js",children:"const Piscina = require('piscina');\nconst pool = new Piscina({\n  worker: '/absolute/path/to/worker.js',\n  niceIncrement: 20\n});\n"})}),"\n",(0,t.jsxs)(n.p,{children:["The higher the ",(0,t.jsx)(n.code,{children:"niceIncrement"}),", the lower the CPU scheduling priority will be\nfor the pooled workers which will generally extend the execution time of\nCPU-bound tasks but will help prevent those threads from stealing CPU time from\nthe main Node.js event loop thread. Whether this is a good thing or not depends\nentirely on your application and will require careful profiling to get correct."]}),"\n",(0,t.jsxs)(n.p,{children:["The key metrics to pay attention to when tuning the ",(0,t.jsx)(n.code,{children:"niceIncrement"})," are the\nsampled run times of the tasks in the worker pool (using the [",(0,t.jsx)(n.code,{children:"runTime"}),"][]\nproperty) and the [delay of the Node.js main thread event loop][]."]}),"\n",(0,t.jsx)(n.h3,{id:"multiple-thread-pools-and-embedding-piscina-as-a-dependency",children:"Multiple Thread Pools and Embedding Piscina as a Dependency"}),"\n",(0,t.jsxs)(n.p,{children:["Every ",(0,t.jsx)(n.code,{children:"Piscina"})," instance creates a separate pool of threads and operates\nwithout any awareness of the other. When multiple pools are created in a\nsingle application the various threads may contend with one another, and\nwith the Node.js main event loop thread, and may cause an overall reduction\nin system performance."]}),"\n",(0,t.jsxs)(n.p,{children:["Modules that embed Piscina as a dependency ",(0,t.jsx)(n.em,{children:"should"})," make it clear via\ndocumentation that threads are being used. It would be ideal if those\nwould make it possible for users to provide an existing ",(0,t.jsx)(n.code,{children:"Piscina"})," instance\nas a configuration option in lieu of always creating their own."]})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(l,{...e})}):l(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>s,x:()=>r});var t=i(6540);const o={},a=t.createContext(o);function s(e){const n=t.useContext(a);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),t.createElement(a.Provider,{value:n},e.children)}}}]);